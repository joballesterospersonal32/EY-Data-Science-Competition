{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Phase 3: Enhanced Feature Modeling\n",
    "\n",
    "This notebook reproduces and extends the Benchmark Model experiment using the **enhanced spectral indices** generated in Phase 2.\n",
    "\n",
    "## Objectives\n",
    "1. Load the enhanced Landsat feature set from `landsat_features_training_enhanced.csv`\n",
    "2. Reproduce the benchmark Random Forest pipeline for a fair apples-to-apples comparison\n",
    "3. Train an enhanced model using all 18 new spectral indices + PET + temporal features\n",
    "4. Compare performance metrics against the benchmark\n",
    "5. Plot feature importances for each target\n",
    "6. Generate submission predictions using the best model\n",
    "\n",
    "## Benchmark Results (to beat)\n",
    "| Parameter | R² Train | RMSE Train | R² Test | RMSE Test |\n",
    "|---|---|---|---|---|\n",
    "| Total Alkalinity | 0.903 | 23.12 | 0.546 | 50.88 |\n",
    "| Electrical Conductance | 0.918 | 98.03 | 0.585 | 220.21 |\n",
    "| Dissolved Reactive Phosphorus | 0.882 | 17.45 | 0.529 | 35.18 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Load Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE    = 0.3\n",
    "\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 2: Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water quality labels\n",
    "wq_df = pd.read_csv('water_quality_training_dataset.csv')\n",
    "print(f'Water quality shape:      {wq_df.shape}')\n",
    "\n",
    "# Enhanced Landsat features (produced by 02_Feature_Engineering_Spectral_Indices.ipynb)\n",
    "landsat_train = pd.read_csv('landsat_features_training_enhanced.csv')\n",
    "print(f'Enhanced Landsat train:   {landsat_train.shape}')\n",
    "\n",
    "landsat_val   = pd.read_csv('landsat_features_validation_enhanced.csv')\n",
    "print(f'Enhanced Landsat val:     {landsat_val.shape}')\n",
    "\n",
    "# TerraClimate PET\n",
    "tc_train = pd.read_csv('terraclimate_features_training.csv')\n",
    "tc_val   = pd.read_csv('terraclimate_features_validation.csv')\n",
    "print(f'TerraClimate train:       {tc_train.shape}')\n",
    "print(f'TerraClimate val:         {tc_val.shape}')\n",
    "\n",
    "# Submission template\n",
    "submission_template = pd.read_csv('submission_template.csv')\n",
    "print(f'Submission template:      {submission_template.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 3: Merge Datasets & Add Temporal Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_frame(wq, landsat, terraclimate):\n",
    "    \"\"\"\n",
    "    Concatenate water-quality labels, enhanced Landsat bands/indices,\n",
    "    and TerraClimate PET into a single training DataFrame.\n",
    "    Duplicate columns (Lat/Lon/Date) are removed after concat.\n",
    "    \"\"\"\n",
    "    df = pd.concat([wq, landsat, terraclimate], axis=1)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Extract month and year from 'Sample Date' as numeric features.\n",
    "    Month captures seasonality; year captures any long-term drift.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    dates = pd.to_datetime(df['Sample Date'], dayfirst=True, errors='coerce')\n",
    "    df['Month'] = dates.dt.month.astype(float)\n",
    "    df['Year']  = dates.dt.year.astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = build_training_frame(wq_df, landsat_train, tc_train)\n",
    "train_df = add_temporal_features(train_df)\n",
    "\n",
    "print(f'Merged training shape: {train_df.shape}')\n",
    "print(f'Columns: {list(train_df.columns)}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 4: Handle Missing Values (Median Imputation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values before imputation:')\n",
    "missing = train_df.isnull().sum()\n",
    "print(missing[missing > 0].to_string())\n",
    "\n",
    "train_df = train_df.fillna(train_df.median(numeric_only=True))\n",
    "\n",
    "print(f'\\nMissing after imputation: {train_df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 5: Define Feature Sets\n",
    "\n",
    "Two feature sets are defined for a controlled comparison:\n",
    "\n",
    "- **`BASELINE_FEATURES`** — identical to the Benchmark notebook (`swir22`, `NDMI`, `MNDWI`, `pet`)\n",
    "- **`ENHANCED_FEATURES`** — all 18 spectral indices from Phase 2 + raw bands + PET + temporal features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "\n",
    "BASELINE_FEATURES = ['swir22', 'NDMI', 'MNDWI', 'pet']\n",
    "\n",
    "ENHANCED_FEATURES = [\n",
    "    # Raw bands\n",
    "    'nir', 'green', 'swir16', 'swir22',\n",
    "    # Baseline indices\n",
    "    'NDMI', 'MNDWI',\n",
    "    # New vegetation / water indices\n",
    "    'NDVI', 'NDWI', 'NDSI_water', 'NDTI',\n",
    "    'Turbidity_Index', 'Chlorophyll_Proxy', 'BSI',\n",
    "    # Band ratios\n",
    "    'SWIR22_NIR_ratio', 'SWIR16_NIR_ratio', 'Green_NIR_ratio',\n",
    "    'SWIR22_Green_ratio', 'SWIR16_Green_ratio',\n",
    "    # Log-transformed bands\n",
    "    'log_nir', 'log_green', 'log_swir16', 'log_swir22',\n",
    "    # Quadratic terms\n",
    "    'nir_squared', 'swir22_squared',\n",
    "    # Climate\n",
    "    'pet',\n",
    "    # Temporal\n",
    "    'Month', 'Year',\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist after merging\n",
    "ENHANCED_FEATURES = [c for c in ENHANCED_FEATURES if c in train_df.columns]\n",
    "\n",
    "print(f'Baseline feature count:  {len(BASELINE_FEATURES)}')\n",
    "print(f'Enhanced feature count:  {len(ENHANCED_FEATURES)}')\n",
    "print(f'\\nEnhanced features:\\n{ENHANCED_FEATURES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Step 6: Helper Functions (Pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "\n",
    "def train_model(X_train_scaled, y_train, n_estimators=200):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_scaled, y_true, dataset_name='Test'):\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f'  {dataset_name:6s} — R²: {r2:.4f}  |  RMSE: {rmse:.4f}')\n",
    "    return y_pred, r2, rmse\n",
    "\n",
    "\n",
    "def run_pipeline(df, feature_cols, target_col, label=''):\n",
    "    \"\"\"\n",
    "    Full pipeline: split → scale → train → evaluate.\n",
    "    Returns (model, scaler, results_dict).\n",
    "    \"\"\"\n",
    "    print(f'\\n  Target: {target_col}')\n",
    "    X = df[feature_cols].values\n",
    "    y = df[target_col].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    X_train_sc, X_test_sc, scaler    = scale_data(X_train, X_test)\n",
    "    model = train_model(X_train_sc, y_train)\n",
    "\n",
    "    _, r2_tr, rmse_tr = evaluate_model(model, X_train_sc, y_train, 'Train')\n",
    "    _, r2_te, rmse_te = evaluate_model(model, X_test_sc,  y_test,  'Test')\n",
    "\n",
    "    results = {\n",
    "        'Model':       label,\n",
    "        'Parameter':   target_col,\n",
    "        'R2_Train':    round(r2_tr,   4),\n",
    "        'RMSE_Train':  round(rmse_tr, 4),\n",
    "        'R2_Test':     round(r2_te,   4),\n",
    "        'RMSE_Test':   round(rmse_te, 4),\n",
    "    }\n",
    "    return model, scaler, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Step 7: Baseline Experiment (Reproduce Benchmark)\n",
    "\n",
    "Using the same 4 features as the official benchmark notebook: `swir22`, `NDMI`, `MNDWI`, `pet`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('BASELINE MODEL  (swir22, NDMI, MNDWI, pet)')\n",
    "print('=' * 60)\n",
    "\n",
    "baseline_results = []\n",
    "baseline_models  = {}\n",
    "baseline_scalers = {}\n",
    "\n",
    "for target in TARGETS:\n",
    "    model, scaler, res = run_pipeline(\n",
    "        train_df, BASELINE_FEATURES, target, label='Baseline'\n",
    "    )\n",
    "    baseline_models[target]  = model\n",
    "    baseline_scalers[target] = scaler\n",
    "    baseline_results.append(res)\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "print('\\nBaseline Summary:')\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 8: Enhanced Experiment (All Spectral Indices + Temporal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('ENHANCED MODEL  (all spectral indices + PET + temporal)')\n",
    "print('=' * 60)\n",
    "\n",
    "enhanced_results = []\n",
    "enhanced_models  = {}\n",
    "enhanced_scalers = {}\n",
    "\n",
    "for target in TARGETS:\n",
    "    model, scaler, res = run_pipeline(\n",
    "        train_df, ENHANCED_FEATURES, target, label='Enhanced'\n",
    "    )\n",
    "    enhanced_models[target]  = model\n",
    "    enhanced_scalers[target] = scaler\n",
    "    enhanced_results.append(res)\n",
    "\n",
    "enhanced_df = pd.DataFrame(enhanced_results)\n",
    "print('\\nEnhanced Summary:')\n",
    "enhanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 9: Performance Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.concat([baseline_df, enhanced_df], ignore_index=True)\n",
    "\n",
    "print('Full Comparison Table:')\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Delta\n",
    "delta_rows = []\n",
    "for target in TARGETS:\n",
    "    b = baseline_df[baseline_df['Parameter'] == target].iloc[0]\n",
    "    e = enhanced_df[enhanced_df['Parameter'] == target].iloc[0]\n",
    "    delta_rows.append({\n",
    "        'Parameter':      target,\n",
    "        'ΔR²_Test':       round(e['R2_Test']   - b['R2_Test'],   4),\n",
    "        'ΔRMSE_Test':     round(e['RMSE_Test']  - b['RMSE_Test'], 4),\n",
    "    })\n",
    "\n",
    "delta_df = pd.DataFrame(delta_rows)\n",
    "print('\\nDelta (Enhanced − Baseline):')\n",
    "print(delta_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "metrics = ['R2_Test', 'RMSE_Test']\n",
    "titles  = ['Test R²  (higher is better)', 'Test RMSE  (lower is better)']\n",
    "\n",
    "x = np.arange(len(TARGETS))\n",
    "width = 0.35\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics, titles):\n",
    "    b_vals = [baseline_df[baseline_df['Parameter'] == t][metric].values[0] for t in TARGETS]\n",
    "    e_vals = [enhanced_df[enhanced_df['Parameter'] == t][metric].values[0] for t in TARGETS]\n",
    "\n",
    "    bars_b = ax.bar(x - width/2, b_vals, width, label='Baseline', color='steelblue', alpha=0.8)\n",
    "    bars_e = ax.bar(x + width/2, e_vals, width, label='Enhanced', color='coral',     alpha=0.8)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Total Alk.', 'Elec. Cond.', 'DRP'], fontsize=10)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.legend()\n",
    "\n",
    "    for bar in bars_b:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars_e:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Baseline vs Enhanced Model — Out-of-Sample Performance', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Step 10: Feature Importance (Enhanced Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "for ax, target in zip(axes, TARGETS):\n",
    "    model = enhanced_models[target]\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_n = 15\n",
    "    top_idx   = indices[:top_n]\n",
    "    top_names = [ENHANCED_FEATURES[i] for i in top_idx]\n",
    "    top_vals  = importances[top_idx]\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.85, top_n))\n",
    "    ax.barh(range(top_n), top_vals[::-1], color=colors)\n",
    "    ax.set_yticks(range(top_n))\n",
    "    ax.set_yticklabels(top_names[::-1], fontsize=9)\n",
    "    ax.set_xlabel('Importance', fontsize=10)\n",
    "    ax.set_title(f'{target}\\n(Top {top_n} features)', fontsize=11)\n",
    "\n",
    "plt.suptitle('Feature Importances — Enhanced Random Forest', fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_enhanced.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Step 11: Prepare Validation Data & Generate Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build validation frame from enhanced Landsat + TerraClimate val\n",
    "val_df = pd.concat([landsat_val, tc_val], axis=1)\n",
    "val_df = val_df.loc[:, ~val_df.columns.duplicated()]\n",
    "val_df = add_temporal_features(val_df)\n",
    "\n",
    "# Impute with training medians so no data leakage from validation set\n",
    "train_medians = train_df[ENHANCED_FEATURES].median()\n",
    "for col in ENHANCED_FEATURES:\n",
    "    if col in val_df.columns:\n",
    "        val_df[col] = val_df[col].fillna(train_medians[col])\n",
    "    else:\n",
    "        val_df[col] = train_medians[col]\n",
    "\n",
    "print(f'Validation shape: {val_df.shape}')\n",
    "print(f'Missing after imputation: {val_df[ENHANCED_FEATURES].isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df[ENHANCED_FEATURES].values\n",
    "\n",
    "pred_TA  = enhanced_models['Total Alkalinity'].predict(\n",
    "    enhanced_scalers['Total Alkalinity'].transform(X_val)\n",
    ")\n",
    "pred_EC  = enhanced_models['Electrical Conductance'].predict(\n",
    "    enhanced_scalers['Electrical Conductance'].transform(X_val)\n",
    ")\n",
    "pred_DRP = enhanced_models['Dissolved Reactive Phosphorus'].predict(\n",
    "    enhanced_scalers['Dissolved Reactive Phosphorus'].transform(X_val)\n",
    ")\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Latitude':                     submission_template['Latitude'].values,\n",
    "    'Longitude':                    submission_template['Longitude'].values,\n",
    "    'Sample Date':                  submission_template['Sample Date'].values,\n",
    "    'Total Alkalinity':             pred_TA,\n",
    "    'Electrical Conductance':       pred_EC,\n",
    "    'Dissolved Reactive Phosphorus': pred_DRP,\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_enhanced.csv', index=False)\n",
    "print(f'Submission saved: submission_enhanced.csv  ({submission_df.shape})')\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Step 12: Predicted Value Distributions (Sanity Check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "preds  = [pred_TA, pred_EC, pred_DRP]\n",
    "labels = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen']\n",
    "\n",
    "for ax, pred, label, color in zip(axes, preds, labels, colors):\n",
    "    ax.hist(pred, bins=30, color=color, edgecolor='white', alpha=0.85)\n",
    "    ax.axvline(train_df[label].median(), color='black', linestyle='--',\n",
    "               linewidth=1.5, label=f'Train median')\n",
    "    ax.set_title(label, fontsize=11)\n",
    "    ax.set_xlabel('Predicted Value')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Distribution of Validation Predictions vs Training Median', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('submission_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Model | Feature Count | TA R² Test | EC R² Test | DRP R² Test |\n",
    "|---|---|---|---|---|\n",
    "| **Benchmark (original)** | 4 | 0.546 | 0.585 | 0.529 |\n",
    "| **Baseline (reproduced)** | 4 | see above | see above | see above |\n",
    "| **Enhanced** | 27 | see above | see above | see above |\n",
    "\n",
    "### Key improvements over the benchmark\n",
    "- Added 18 physics-motivated spectral indices (NDVI, NDWI, NDTI, Turbidity Index, Chlorophyll Proxy, BSI, band ratios, log-transformed bands, quadratic terms)\n",
    "- Added raw Landsat bands (`nir`, `green`, `swir16`) which the benchmark excluded\n",
    "- Added `Month` and `Year` as temporal features to capture seasonality\n",
    "- Used training medians (not validation medians) for imputation to prevent leakage\n",
    "- Increased `n_estimators` to 200 and tuned `min_samples_leaf` for better generalisation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eychallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
