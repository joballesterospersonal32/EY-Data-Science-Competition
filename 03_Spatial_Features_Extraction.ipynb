{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2, Step 4: Spatial Features Extraction (Elevation & Land Cover)\n",
    "\n",
    "This notebook extracts **spatial features**—elevation and land cover—for water quality prediction. These features help explain water quality drivers because:\n",
    "\n",
    "- **Elevation** influences runoff, groundwater flow, and pollutant transport\n",
    "- **Land cover** (e.g., forest vs. cropland vs. urban) affects erosion, nutrient runoff, and sedimentation\n",
    "\n",
    "## Objectives\n",
    "1. Load sample locations from Landsat training and validation data\n",
    "2. Extract elevation from Copernicus DEM (30m resolution)\n",
    "3. Extract land cover from ESA WorldCover (10m resolution)\n",
    "4. Save spatial feature datasets for model integration\n",
    "\n",
    "## Data Sources\n",
    "- **Copernicus DEM GLO-30**: Global 30m elevation from TanDEM-X radar\n",
    "- **ESA WorldCover**: Global 10m land cover classification (11 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Dependencies and Data\n",
    "\n",
    "We import the same stack used in other EY notebooks: `pystac_client` and `planetary_computer` for STAC API access, `rasterio` for reading cloud-optimized GeoTIFFs, and `pandas` for data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample locations from Landsat feature files...\n",
      "Training samples: 9319\n",
      "Validation samples: 200\n",
      "Columns: ['Latitude', 'Longitude', 'Sample Date', 'nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date      nir    green   swir16   swir22  \\\n",
       "0 -28.760833  17.730278  02-01-2011  11190.0  11426.0   7687.5   7645.0   \n",
       "1 -26.861111  28.884722  03-01-2011  17658.5   9550.0  13746.5  10574.0   \n",
       "2 -26.450000  28.085833  03-01-2011  15210.0  10720.0  17974.0  14201.0   \n",
       "3 -27.671111  27.236944  03-01-2011  14887.0  10943.0  13522.0  11403.0   \n",
       "4 -27.356667  27.286389  03-01-2011  16828.5   9502.5  12665.5   9643.0   \n",
       "\n",
       "       NDMI     MNDWI  \n",
       "0  0.185538  0.195595  \n",
       "1  0.124566 -0.180134  \n",
       "2 -0.083293 -0.252805  \n",
       "3  0.048048 -0.105416  \n",
       "4  0.141147 -0.142683  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Landsat training and validation data (source of sample locations)\n",
    "print(\"Loading sample locations from Landsat feature files...\")\n",
    "landsat_train = pd.read_csv(\"landsat_features_training.csv\")\n",
    "landsat_val = pd.read_csv(\"landsat_features_validation.csv\")\n",
    "\n",
    "print(f\"Training samples: {len(landsat_train)}\")\n",
    "print(f\"Validation samples: {len(landsat_val)}\")\n",
    "print(f\"Columns: {list(landsat_train.columns)}\")\n",
    "\n",
    "# We need Latitude, Longitude, Sample Date for merging later\n",
    "train_coords = landsat_train[[\"Latitude\", \"Longitude\", \"Sample Date\"]].copy()\n",
    "val_coords = landsat_val[[\"Latitude\", \"Longitude\", \"Sample Date\"]].copy()\n",
    "\n",
    "landsat_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Elevation from Copernicus DEM\n",
    "\n",
    "We use the **Copernicus DEM GLO-30** (30m resolution) from the Microsoft Planetary Computer. The DEM is derived from TanDEM-X radar. Elevation (meters above mean sea level) influences:\n",
    "\n",
    "- Runoff and erosion\n",
    "- Groundwater discharge\n",
    "\n",
    "**Approach**: For each sample point, we search for the DEM tile containing that point, load the tile, and sample the elevation value at (lon, lat). We cache tiles to avoid repeated loads when many points fall in the same tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_elevation_for_points(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extract elevation (meters) at each (Latitude, Longitude) using Copernicus DEM GLO-30.\n",
    "    Returns a Series with elevation values aligned to the input DataFrame index.\n",
    "    \"\"\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=pc.sign_inplace,\n",
    "    )\n",
    "\n",
    "    # Study region bbox (Southern Africa)\n",
    "    bbox = [14.97, -35.18, 32.79, -21.72]  # [min_lon, min_lat, max_lon, max_lat]\n",
    "    search = catalog.search(\n",
    "        collections=[\"cop-dem-glo-30\"],\n",
    "        bbox=bbox,\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print(f\"Found {len(items)} Copernicus DEM tiles covering the study region\")\n",
    "\n",
    "    # Map each item to its geometry for point-in-tile checks\n",
    "    def get_bbox(item):\n",
    "        coords = item.geometry[\"coordinates\"][0]\n",
    "        lons = [c[0] for c in coords]\n",
    "        lats = [c[1] for c in coords]\n",
    "        return min(lons), min(lats), max(lons), max(lats)\n",
    "\n",
    "    item_bboxes = [(item, get_bbox(item)) for item in items]\n",
    "\n",
    "    def find_tile_for_point(lon, lat):\n",
    "        for item, (min_lon, min_lat, max_lon, max_lat) in item_bboxes:\n",
    "            if min_lon <= lon <= max_lon and min_lat <= lat <= max_lat:\n",
    "                return item\n",
    "        return None\n",
    "\n",
    "    # Asset key for elevation band\n",
    "    elevation_asset_key = \"data\"\n",
    "\n",
    "    # Cache: tile_id -> opened rasterio dataset (we'll sample and close per tile)\n",
    "    tile_cache = {}\n",
    "\n",
    "    elevations = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting elevation\"):\n",
    "        lat = row[\"Latitude\"]\n",
    "        lon = row[\"Longitude\"]\n",
    "        item = find_tile_for_point(lon, lat)\n",
    "        if item is None:\n",
    "            elevations.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        asset = item.assets.get(elevation_asset_key) or item.assets.get(\"elevation\")\n",
    "        if asset is None:\n",
    "            elevations.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        tile_id = item.id\n",
    "        try:\n",
    "            if tile_id not in tile_cache:\n",
    "                signed_asset = pc.sign(asset)\n",
    "                tile_cache[tile_id] = rasterio.open(signed_asset.href)\n",
    "            src = tile_cache[tile_id]\n",
    "            # rasterio sample expects (x, y) = (lon, lat) in EPSG:4326\n",
    "            vals = list(src.sample([(lon, lat)]))\n",
    "            if vals:\n",
    "                v = float(vals[0][0])\n",
    "                # Copernicus uses -32768 as nodata\n",
    "                elevations.append(np.nan if v <= -32768 else v)\n",
    "            else:\n",
    "                elevations.append(np.nan)\n",
    "        except Exception as e:\n",
    "            elevations.append(np.nan)\n",
    "\n",
    "    # Close cached datasets\n",
    "    for ds in tile_cache.values():\n",
    "        ds.close()\n",
    "\n",
    "    return pd.Series(elevations, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting elevation for training data...\n",
      "Found 226 Copernicus DEM tiles covering the study region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting elevation: 100%|██████████| 9319/9319 [01:01<00:00, 150.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting elevation for validation data...\n",
      "Found 226 Copernicus DEM tiles covering the study region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting elevation: 100%|██████████| 200/200 [00:08<00:00, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training elevation summary (m): count    9319.000000\n",
      "mean      909.345318\n",
      "std       515.518178\n",
      "min         2.463319\n",
      "25%       369.233032\n",
      "50%      1082.105591\n",
      "75%      1315.000000\n",
      "max      1590.156738\n",
      "Name: elevation, dtype: float64\n",
      "Validation elevation summary (m): count    200.000000\n",
      "mean     379.425071\n",
      "std      334.774593\n",
      "min        2.000000\n",
      "25%      129.090591\n",
      "50%      192.466599\n",
      "75%      773.500000\n",
      "max      979.294922\n",
      "Name: elevation, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract elevation for training and validation\n",
    "print(\"Extracting elevation for training data...\")\n",
    "train_elev = extract_elevation_for_points(train_coords)\n",
    "train_coords[\"elevation\"] = train_elev\n",
    "\n",
    "print(\"\\nExtracting elevation for validation data...\")\n",
    "val_elev = extract_elevation_for_points(val_coords)\n",
    "val_coords[\"elevation\"] = val_elev\n",
    "\n",
    "print(f\"\\nTraining elevation summary (m): {train_coords['elevation'].describe()}\")\n",
    "print(f\"Validation elevation summary (m): {val_coords['elevation'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract Land Cover from ESA WorldCover\n",
    "\n",
    "**ESA WorldCover** provides global land cover at 10m resolution with 11 classes (e.g., Tree cover, Cropland, Built-up, Permanent water bodies). Land cover strongly influences water quality through:\n",
    "\n",
    "- Urban/agricultural runoff (nutrients, sediments)\n",
    "- Vegetation buffering and erosion control\n",
    "\n",
    "**Note**: WorldCover 2020 is used as a proxy for land cover during 2011–2015. Land cover changes slowly, so this provides useful spatial context.\n",
    "\n",
    "**Class codes**: 10=Tree cover, 20=Shrubland, 30=Grassland, 40=Cropland, 50=Built-up, 60=Bare, 70=Snow/ice, 80=Water bodies, 90=Herbaceous wetland, 95=Mangroves, 100=Moss/lichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_land_cover_for_points(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extract land cover class at each (Latitude, Longitude) using ESA WorldCover 2020.\n",
    "    Returns a Series with land cover codes aligned to the input DataFrame index.\n",
    "    \"\"\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=pc.sign_inplace,\n",
    "    )\n",
    "\n",
    "    bbox = [14.97, -35.18, 32.79, -21.72]\n",
    "    search = catalog.search(\n",
    "        collections=[\"esa-worldcover\"],\n",
    "        bbox=bbox,\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print(f\"Found {len(items)} ESA WorldCover tiles covering the study region\")\n",
    "\n",
    "    def get_bbox(item):\n",
    "        coords = item.geometry[\"coordinates\"][0]\n",
    "        lons = [c[0] for c in coords]\n",
    "        lats = [c[1] for c in coords]\n",
    "        return min(lons), min(lats), max(lons), max(lats)\n",
    "\n",
    "    item_bboxes = [(item, get_bbox(item)) for item in items]\n",
    "\n",
    "    def find_tile_for_point(lon, lat):\n",
    "        for item, (min_lon, min_lat, max_lon, max_lat) in item_bboxes:\n",
    "            if min_lon <= lon <= max_lon and min_lat <= lat <= max_lat:\n",
    "                return item\n",
    "        return None\n",
    "\n",
    "    asset_key = \"map\"\n",
    "    tile_cache = {}\n",
    "\n",
    "    land_cover = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting land cover\"):\n",
    "        lat = row[\"Latitude\"]\n",
    "        lon = row[\"Longitude\"]\n",
    "        item = find_tile_for_point(lon, lat)\n",
    "        if item is None:\n",
    "            land_cover.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        asset = item.assets.get(asset_key)\n",
    "        if asset is None:\n",
    "            land_cover.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        tile_id = item.id\n",
    "        try:\n",
    "            if tile_id not in tile_cache:\n",
    "                signed_asset = pc.sign(asset)\n",
    "                tile_cache[tile_id] = rasterio.open(signed_asset.href)\n",
    "            src = tile_cache[tile_id]\n",
    "            vals = list(src.sample([(lon, lat)]))\n",
    "            if vals:\n",
    "                v = int(vals[0][0])\n",
    "                land_cover.append(v)\n",
    "            else:\n",
    "                land_cover.append(np.nan)\n",
    "        except Exception:\n",
    "            land_cover.append(np.nan)\n",
    "\n",
    "    for ds in tile_cache.values():\n",
    "        ds.close()\n",
    "\n",
    "    return pd.Series(land_cover, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting land cover for training data...\n",
      "Found 62 ESA WorldCover tiles covering the study region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting land cover: 100%|██████████| 9319/9319 [00:34<00:00, 271.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting land cover for validation data...\n",
      "Found 62 ESA WorldCover tiles covering the study region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting land cover: 100%|██████████| 200/200 [00:04<00:00, 44.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Land cover value counts (training):\n",
      "land_cover\n",
      "10    2869\n",
      "20    1075\n",
      "30    2885\n",
      "40     204\n",
      "50     357\n",
      "60     352\n",
      "80    1577\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract land cover for training and validation\n",
    "print(\"Extracting land cover for training data...\")\n",
    "train_lc = extract_land_cover_for_points(train_coords)\n",
    "train_coords[\"land_cover\"] = train_lc\n",
    "\n",
    "print(\"\\nExtracting land cover for validation data...\")\n",
    "val_lc = extract_land_cover_for_points(val_coords)\n",
    "val_coords[\"land_cover\"] = val_lc\n",
    "\n",
    "print(\"\\nLand cover value counts (training):\")\n",
    "print(train_coords[\"land_cover\"].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Save Spatial Feature Datasets\n",
    "\n",
    "We save CSVs with `Latitude`, `Longitude`, `Sample Date`, `elevation`, and `land_cover`. These can be merged with Landsat and TerraClimate features in Phase 2, Step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved spatial_features_training.csv (9319 rows)\n",
      "Saved spatial_features_validation.csv (200 rows)\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>elevation</th>\n",
       "      <th>land_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1520.538940</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1470.731201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1338.717163</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1357.407837</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-27.010111</td>\n",
       "      <td>26.698083</td>\n",
       "      <td>04-01-2011</td>\n",
       "      <td>1281.680786</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-25.127778</td>\n",
       "      <td>27.628889</td>\n",
       "      <td>04-01-2011</td>\n",
       "      <td>951.590576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-25.206390</td>\n",
       "      <td>27.558000</td>\n",
       "      <td>04-01-2011</td>\n",
       "      <td>950.862854</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-24.695140</td>\n",
       "      <td>27.409060</td>\n",
       "      <td>04-01-2011</td>\n",
       "      <td>912.183167</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-26.984722</td>\n",
       "      <td>26.632278</td>\n",
       "      <td>04-01-2011</td>\n",
       "      <td>1277.647705</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date    elevation  land_cover\n",
       "0 -28.760833  17.730278  02-01-2011   163.000000          80\n",
       "1 -26.861111  28.884722  03-01-2011  1520.538940          30\n",
       "2 -26.450000  28.085833  03-01-2011  1470.731201          30\n",
       "3 -27.671111  27.236944  03-01-2011  1338.717163          30\n",
       "4 -27.356667  27.286389  03-01-2011  1357.407837          30\n",
       "5 -27.010111  26.698083  04-01-2011  1281.680786          10\n",
       "6 -25.127778  27.628889  04-01-2011   951.590576          20\n",
       "7 -25.206390  27.558000  04-01-2011   950.862854          30\n",
       "8 -24.695140  27.409060  04-01-2011   912.183167          80\n",
       "9 -26.984722  26.632278  04-01-2011  1277.647705          30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_train = \"spatial_features_training.csv\"\n",
    "out_val = \"spatial_features_validation.csv\"\n",
    "\n",
    "train_coords.to_csv(out_train, index=False)\n",
    "val_coords.to_csv(out_val, index=False)\n",
    "\n",
    "print(f\"Saved {out_train} ({len(train_coords)} rows)\")\n",
    "print(f\"Saved {out_val} ({len(val_coords)} rows)\")\n",
    "print(\"\\nPreview:\")\n",
    "train_coords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Phase 2, Step 5: Create temporal features\n",
    "- Phase 2, Step 6: Combine all features (Landsat, TerraClimate, spatial, temporal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eycomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
